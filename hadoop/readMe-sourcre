

ApplicationMaster管理涉及到了4大类,ApplicationMasterLauncher,AMLivelinessMonitor,ApplicationMasterService,以及ApplicationMaster自身类.
    下面介绍一下这些类的用途,在Yarn中,每个类都会有自己明确的功能模块的区分.

      1.ApplicationMasterLauncher--姑且叫做AM启动关闭事件处理器,他既是一个服务也是一个处理器,在这个类中,只处理2类事件,launch和cleanup事件.分别对应启动应用和关闭应用的情形.

      2.AMLivelinessMonitor--这个类从名字上可以看出他是监控类,监控的对象是AM存活状态的监控类,检测的方法与之前的HDFS一样,都是采用heartbeat的方式,如果有节点过期了,将会触发一次过期事件.

      3.ApplicationMasterService--AM请求服务处理类.AMS存在于ResourceManager,中,服务的对象是各个节点上的ApplicationMaster,负责接收各个AM的注册请求,更新心跳包信息等.

      4.ApplicationMaster--节点应用管理类,简单的说,ApplicationMaster负责管理整个应用的生命周期.

ResourceManager中的NM节点管理

      1.NodeManager.java--节点管理类,这个类是yarn-resourcemanager包中的类,不是yarn-nodemanager中的同名类,这个类是本篇文章的核心角色类,

      2.NodesListManager--节点列表管理类，这个类中管理了类似黑名单，白名单的节点列表形式。

      3.NMLivelinessMonitor--节点存活状态监控线程类，与之前的AMLivelinessMonitor线程的原理类似，最简单的心跳更新检查。

      4.ResourceTrackerService--节点服务管理对象，负责与各个NodeManager通信。包括NM在此服务上的注册请求处理，心跳更新操作等等。

ResourceManager HA之应用状态存储与恢复
                         RmState
          ApplicationState   ApplicationState
   ApplicationAttemptState ..

         RmStateStore应用状态保存的方式：
             1.MemoryRMStateStore--信息状态保存在内存中的实现类。
             2.FileSystemRMStateStore--信息状态保存在HDFS文件系统中，这个是做了持久化了。
             3.NullRMStateStore--do nothing，什么都不做，就是不保存应用状态信息。
             4.ZKRMStateStore--信息状态保存在Zookeeper中。

         RMDelegationonTokenIdentifier：保存RM身份标识位到时间的映射,可以用来表名此RM是旧的,还是新启动的RM

Journalnode
       排查公司Hadoop集群性能问题时,发现Hadoop集群整体处理速度非常缓慢,平时只需要跑几十分钟的任务时间一下子上张到了个把小时,起初怀疑是网络原因,
    后来证明的确是有一部分这块的原因,但是过了没几天,问题又重现了,这次就比较难定位问题了,后来分析hdfs请求日志和Ganglia的各项监控指标,
    发现namenode的挤压请求数持续比较大,说明namenode处理速度异常,然后进而分析出是因为写journalnode的editlog速度慢问题导致的,
    后来发现的确是journalnode的问题引起的,后来的原因是因为journalnode的editlog目录没创建,导致某台节点写edillog一直抛FileNotFoundException,
    所以在这里提醒大家一定要重视一些小角色,比如JournalNode.

    journalNode的作用是存放EditLog的,在MR1中editlog是和fsimage存放在一起的然后SecondNamenode做定期合并
    QuorumJournalManager:
       在配置中定义JournalNode节点的个数是可多个的,所以一定会存在一个类似管理者这样的角色存在,而这个管理者就是QJM,全程QuorumJournalManager
       JournalManager可以写很多记录数据给多个远程JournalNode节点
       private final AsyncLoggerSet loggers,在此对象中包含了AsyncLogger对象列表,每个logger对象管控一个独立的Journalnode
       public class IPCLoggerChannel implements AsyncLogger
       因为管道类方法与真正客户端方法继承了相同的协议,方法定义是相同的,下面列举几个常见方法

    singleThreadExecutor单线程线程池一般执行的是写操作相关,而并行线程池则进行的是读操作,而且所有的这些操作采用的异步执行的方式,
    保证了高效性.服务端执行操作函数后,立刻得到一个call列表,并等待回复值

    JournalNode和Journal
    与服务端对应的客户端,对每个JournalNode进行操作执行的类是JournalNode

监控：
        任何分布式系统在不断演变的过程中,必然都会经过有小变到大的过程,中间也必定会由不稳定到逐步稳定的过程.在所有的这些系统能够稳定运行的一个前提是,
     完整的监控和报警系统.这个模块是系统保持稳定最最基础的模块服务.只有在这块功能完善的情况下,才会让系统的维护者更高效的定位到问题所在,减少不必要的时间消耗,
     才会有更多的时间去做其他方面的一些优化.今天我所主要描述的就是对于Hadoop的强大监控工具Ganglia.

        Ganglia是开源的集群监控项目,代码可以在github社区进行下载.Ganglia的架构设计也是类似于Client-Server的模式,
     Client端会开启gmond进程进行客户端监控数据的收集,Server端会拉取client端数据,server端对数据进行收集并进行页面的展示

       监控指标：以点分隔,前半部分是上下文dfs、jvm,后半部分是具体的统计名称
          dfs.NameNode metrics
             (namenode和FSNameSystem调用)
          dfs.datanode metrics --> DataNodeMetrics
             (datanode类中,dataxceiver变量,调用blockReceiver中receiveBlock方法,给datanodeMetrics变量赋值)
          dfs.namenode metrics
          dfs.FSNamesystem metrics
          jvm.JvmMetrics metrics

https://blog.csdn.net/wankunde/article/details/89792117











===========================================================================================================================================
https://blog.csdn.net/u012151684/article/details/108228956
 YARN框架作为一个资源管理系统，其最重要和最基础的两个功能是资源调度和资源隔离：

资源调度：由resourcemanager完成，在resourcemanager的组件及资源调度已有介绍；
资源隔离：各个nodemanager监控隔离完成；
       YARN对其内部所拥有的内存资源和CPU资源采取了不同的资源隔离方案。
       对于内存资源，它是一种限制性资源，它的量的大小直接决定应用程序的死活，因为应用程序到达内存限制，会发生OOM，就会被杀死。
       CPU资源一般用Cgroups进行资源控制。内存资源隔离除Cgroups之外提供了另外一个更灵活的方案，就是线程监控方案。

CPU资源隔离
        默认情况下，NodeManager未启用任何对CPU资源的隔离机制，如果需要启用该机制需使用LinuxContainerExecutor，
    它能够以应用程序提交者的身份创建文件、运行Container和销毁Container。相比于DefaultContainerExecutor采用NodeManager启动者的身份执行这些操作，
    LinuxContainerExecutor具有更高的安全性。LinuxContainerExecutor的核心设计思想是赋予NodeManager启动者以root权限，进而使其拥有足够的权限以任意用户身份执行一些操作，
    从而使得NodeManager执行者可以将Container使用的目录和文件的拥有者修改为应用程序的提交者，并以应用程序提交者的身份运行Container，
    防止所有Container以NodeManager执行者身份运行进而带来的各种风险。上述机制的实现在YARN的NodeManager采用C语言实现了一个setuid功能的工具container-executor，
    该脚本拥有root权限，可以完成任意操作，其可执行脚本位于：/opt/yarn/hadoop/bin/container-executor。YARN正是通过该脚本创建出Cgroups层级树以及完成Cgroups属性设置等操作。


































