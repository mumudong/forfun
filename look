clickhouse   https://blog.csdn.net/china_world/article/details/52687685?locationNum=1
             https://blog.csdn.net/u013676711/article/details/78862243

java -server -Xms3036m -Xmx8240m -verbose:gc -XX:+UseG1GC -XX:PermSize=128m -XX:MaxPermSize=128m -Xss256k -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpP
ath=/export/rtdw/logs/$1.log  -XX:+PrintGCDetails -jar /export/rtdw/translate-11.8.nocheck-SNAPSHOT.jar --spring.profiles.active=pro --dbrep.node.name=
$1 --dbrep.version=$2 --reader.distribute.num=${distributeNum} --log.path=/export/rtdw/logs/$1 >> /export/rtdw/logs/$1/translate.log 2>&1 &
jps -ml|grep TaskRunnerApplicationBootstrap|awk '{print $1}'| xargs -n 1 -I [] awk '/^Swap:/ {SWAP+=$2}END{print SWAP" KB  []"}' /proc/[]/smaps

spark steaming exactly once:
    structured streaming:通过checkpoint wal和可重放的源数据来保证数据不丢失,sink需保证幂等性

flink 使用jobmanager通过checkpointcoordinator向source中发送checkpointbarrier，栅栏流到一个算子，该算子暂停运算，并将自身状态存入statebackend,通过栅栏对齐实现内部exactly once,通过不对齐实现at least once
我程序中Flink的CheckPoint语义设置了 Exactly Once，但是我的mysql中看到数据重复了？程序中设置了1分钟1次CheckPoint，但是5秒向mysql写一次数据，并commit；
      答：Flink要求end to end的精确一次都必须实现TwoPhaseCommitSinkFunction。如果你的chk-100成功了，过了30秒，由于5秒commit一次，所以实际上已经写入了6批数据进入mysql，但是突然程序挂了，从chk100处恢复，这样的话，之前提交的6批数据就会重复写入，所以出现了重复消费。Flink的精确一次有两种情况，一个是Flink内部的精确一次，一个是端对端的精确一次，这个博客所描述的都是关于Flink内部去的精确一次，我后期再发一个博客详细介绍一下Flink端对端的精确一次如何实现

hive --hiveconf hive.root.logger=DEBUG,console

JSqlParser 0.9.7 发布，SQL 解析工具
第一步：通过MR生成hbase对应HFile文件
第二步：hadoop distcp跨集群拷贝
第三步：bulkload

bulkload注意事项：
    mapreduce方式生成hfile则reducer数量和hbase表预分区数据量一样
    bulkload每个region默认限制Hfile数量小于32个
        hbase.hregion.max.filesize
	hbase.mapreduce.bulkload.max.hfiles.perRegion.perFamily
   bulkload数据量限制为上述两个参数的乘积
http://hbase.apache.org/book.html#arch.bulk.load
http://www.cloudera.com/documentation/enterprise/5-3-x/topics/admin_hbase_import.html

ctrl alt b   查看实现
f12          打开命令行
alt ;        显示当前类结构
ctrl q       显示注释文档
Ctrl + shift + alt + n 查找类中方法或变量
Ctrl+Shift+U 大小写转化

【调试部分、编译】
Ctrl+F2，停止
Alt+Shift+F9，选择 Debug
Alt+Shift+F10，选择 Run
Ctrl+Shift+F9，编译
Ctrl+Shift+F10，运行
Ctrl+Shift+F8，查看断点
F8，步过
F7，步入
Shift+F7，智能步入
Shift+F8，步出
Alt+Shift+F8，强制步过
Alt+Shift+F7，强制步入
Alt+F9，运行至光标处
Ctrl+Alt+F9，强制运行至光标处
F9，恢复程序
Alt+F10，定位到断点
Ctrl+F8，切换行断点

ctrl h
ctrl alt h


clouderal pom配置
pom添加：
<repositories>
	<repository>
		<id>cloudera</id>
		<url>https://repository.cloudera.com/artifactory/cloudera-repos/</url>
		<releases>
			<enabled>true</enabled>
		</releases>
		<snapshots>
			<enabled>true</enabled>
		</snapshots>
	</repository>
</repositories>
修改maven settings.xml
*,!cloudera表示出了aliyun还可以使用cloudera
<mirror>
	<id>nexus-aliyun</id>
	<mirrorOf>*,!cloudera</mirrorOf>
	<name>Nexus aliyun</name>                     
	<url>
	  http://maven.aliyun.com/nexus/content/groups/public
	</url>
</mirror> 
















