通过在Flink命令中指定“savepoint”关键字来触发Savepoints操作，同时需要在命令中指定jobId和targetDirectory（两个参数），其中jobId是需要触发Savepoints操作的Job Id编号，targetDirectory指定Savepoint数据存储路径，所有Savepoint存储的数据都会放置在该配置路径中。
    bin/flink savepoint :jobId [:targetDirectory]
在Hadoop Yarn上提交的应用，需要指定Flink jobId的同时也需要通过使用yid指定YarnAppId，其他参数和普通模式一样。
    bin/flink savepoint :jobId [:targetDirectory] -yid :y
通过cancel命令将停止Flink任务的同时将自动触发Savepoints操作，并把中间状态数据写入磁盘，用以后续的任务恢复。
    bin/flink cancel -s [:targetDirectory] :j

bin/flink run -s :savepointPath [:runArgs]
通过使用run命令将任务从保存的Savepoint中恢复，其中-s参数指定了Savepoint数据存储路径。通常情况下Flink通过使用savepoint可以恢复应用中的状态数据，
但在某些情况下如果应用中的算子和Savepoint中的算子状态可能不一致，例如用户在新的代码中删除了某个算子，这时就会出现任务不能恢复的情况，
此时可以通过--allowNonRestoredState（--n）参数来设置忽略状态无法匹配的问题，让程序能够正常启动和运行。

bin/flink savepoint -d :savepointPath
可以通过以上--dispose（-d）命令释放已经存储的Savepoint数据，这样存储在指定路径中的savepointPath将会被清除掉。

启动一个监听端口
    $ nc -l 9000
flink提交任务
    $ ./bin/flink run examples/streaming/SocketWindowWordCount.jar --port 9000

    $ ./bin/stop-local.sh

flink on yarn: https://my.oschina.net/u/3522232/blog/2051960
     需要拷贝：jersey*,
    export HADOOP_CLASSPATH="/usr/hdp/current/hadoop-client/*:/usr/hdp/current/hadoop-client/lib/*:/usr/hdp/current/hadoop-hdfs-client/*:/usr/hdp/current/hadoop-hdfs-client/lib/*:/usr/hdp/current/hadoop-yarn-client/*:/usr/hdp/current/hadoop-yarn-client/lib/*"
    export HADOOP_USER_NAME=hdfs

    启动yarn session,可以提交多个作业
    yarn session -q可以查看集群资源状态

    ./bin/yarn-session.sh -n 10 -tm 2048 -s 2  前台运行，ctrl + c停止即可
    yarn-session.sh -n 3 -jm 2048 -tm 2048 -s 8 -nm FlinkOnYarnSession -d -st

    -d参数可以后台运行，需要 yarn application -kill 关闭
    绑定到已有的yarn session命令：./bin/yarn-session.sh -id application_1463870264508_0029

    请注意：client期望设置-yn 参数(taskmanager的数量)推荐每次创建yarn cluster独立管理
    ./bin/flink run -m yarn-cluster -yn 2 ./examples/batch/WordCount.jar
./bin/flink run -m yarn-cluster -yn 2 -c mumu.SocketWordCount /opt/test-1.0-SNAPSHOT.jar --port 11199

    修改flink默认日志
    vi /usr/local/flink-1.3.3/conf/log4j.properties
    log4j.appender.file.append=true
    log4j.appender.file.MaxFileSize=100M
    log4j.appender.file.MaxBackupIndex=10
    flink的日志会应用到每个flink应用程序上


flink 的 yarn 客户端通过下面的配置参数来控制容器的故障恢复。这些参数可以通过conf/flink-conf.yaml 或者在启动yarn session的时候通过-D参数来指定。
    yarn.reallocate-failed：这个参数控制了flink是否应该重新分配失败的taskmanager容器。默认是true。
	yarn.maximum-failed-containers：applicationMaster可以接受的容器最大失败次数，达到这个参数，就会认为yarn session失败。默认这个次数和初始化请求的taskmanager数量相等(-n 参数指定的)。
	yarn.application-attempts：applicationMaster重试的次数。如果这个值被设置为1(默认就是1)，当application master失败的时候，yarn session也会失败。设置一个比较大的值的话，yarn会尝试重启applicationMaster。



flink metrics:
      TaskManagerMetricGroup
          TaskManagerJobMetricGroup
                TaskMetricGroup
                     TaskIOMetricGroup
                     OperatorMetricGroup
      JobManagerMetricGroup
          JobManagerJobMetricGroup

   System metrics:
         Master 级别和 Work 级别的 JVM 参数
         Network
   User-defined Metrics:
         User-defined Metrics 现在提及的都是 datastream 的 API，table、sql 可能需要 context 协助，但如果写 UDF，它们其实是大同小异的
         Datastream 的 API 是继承 RichFunction ，继承 RichFunction 才可以有 Metrics 的接口。然后通过 RichFunction 会带来一个 getRuntimeContext().getMetricGroup().addGroup(…) 的方法
   获取metrics:
         1、 WebUI 上看到
         2、其次可以通过 RESTful API 获取，RESTful API 对程序比较友好，比如写自动化脚本或程序，自动化运维和测试，通过 RESTful API 解析返回的 Json 格式对程序比较友好
         3、最后，还可以通过 Metric Reporter 获取，监控主要使用 Metric Reporter 功能。
   了解背景和原理会对使用有更深刻的理解。
         WebUI 和 RESTful API 是通过中心化节点定期查询把各个组件中的 Metrics 拉上来的实现方式。其中，fetch 不一定是实时更新的，默认为 10 秒，所以有可能在 WebUI 和 RESTful API 中刷新的数据不是实时想要得到的数据；
         此外，fetch 有可能不同步，比如两个组件，一边在加另一边没有动，可能是由于某种原因超时没有拉过来，这样是无法更新相关值的，它是 try best 的操作，所以有时我们看到的指标有可能会延迟，或许等待后相关值就更新了。
         MetricReporter 不一样，每一个单独的点直接汇报，它没有中心化节点帮助做聚合。如果想要聚合，需要在第三方系统中进行，比如常见的 TSDB 系统。当然，不是中心化结构也是它的好处，它可以免去中心化节点带来的问题，比如内存放不下等
            metrics.reporters: your_monitor,jmx
            metrics.reporter.jmx.class: org.apache.flink.metrics.jmx.JMXReporter
            metrics.reporter.jmx.port: 1025-10000
            metrics.reporter.your_monitor.class: com.your_company.YourMonitorClass
            metrics.reporter.your_monitor.interval: 10 SECONDS
            metrics.reporter.your_monitor.config.a: your_a_value
            metrics.reporter.your_monitor.config.b: your_b_value




