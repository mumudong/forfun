flink可以通过以下三种模式部署：
    Session Mode
    Per-Job Mode
    Application Mode

    以上方式主要区别在于
        集群生命周期和资源隔离保证
        应用程序的main方法是在客户端还是在集群上执行

Session Mode(会话模式，在yarn上启动一个flink集群，提交的flink任务到该集群，yarn上只能监测一个flink集群任务，无法监测到单个flink任务，需要进入集群服务内部才可看到)   非detach模式
    启动yarno-session
    ./bin/yarn-session.sh -n 10 -tm 8192 -s 32
    提交应用，flink run会自动获取yarn-session的地址,所以可以不指定-m,--jobmanager
    ./bin/flink run ./examples/WordCount.jar  hdfs:///..../LICENSE-2.0.txt hdfs:///.../wordcount-result.txt
        会话模式假定存在已经在运行的集群，并使用该集群的资源来执行任何提交的应用程序。在同一（会话）集群中执行的应用程序使用并因此竞争相同的资源。
    这样做的好处是，您不必为每个提交的作业都创建集群。但是，如果其中一项作业行为不当或关闭了taskmanager，则该taskmanager上运行的所有作业都会
    受到故障的影响。除了对导致故障的作业产生负面影响外，这还意味着潜在的大规模恢复过程。此外，只有一个集群运行多个作业意味着JobManager的负载增加，
    JobManager负责簿记集群中所有作业。

Per-Job Mode   detach模式(分离模式)
    ./bin/flink run -m yarn-cluster -yn 4 -yjm 1024 -ytm 4096 ./examples/WordCount.jar
    以上命令在参数前加上y前缀，-yn表示TaskManager个数。
    在这个模式下，同样可以使用-m yarn-cluster提交一个"运行后即焚"的detached yarn（-yd）作业到yarn cluster。

         为了提供更好的资源隔离保证，Per-Job模式使用可用的集群管理器框架（例如YARN，Kubernetes）为每个提交的作业启动集群。该群集仅适用于该作业。
    作业完成后，集群将被torn down，所有附属的资源（文件等）将被清除。这提供了更好的资源隔离，因为行为不当的工作只能拖垮其自己的taskmanager。
    另外，由于每个作业有一个，因此它可以将簿记工作分散到多个JobManager中。== 由于这些原因，由于许多生产原因，首选工作资源分配模型是首选模式。


Application Mode
          在上述所有模式下，应用程序的main方法都是在客户端执行的。此过程包括本地下载应用程序的依赖项，执行main提取Flink运行时可以理解的应用程序
    表示形式（即JobGraph），并将依赖项和JobGraph运送到集群中。这使客户端成为大量的资源消耗者，因为它可能需要大量的网络带宽来下载依赖项并将二进制
    文件运送到群集，并且需要CPU周期来执行main。当跨用户共享客户端时，此问题可能更加明显。
          基于此，“应用程序模式”将为每个提交的应用程序创建一个集群，但是这次，该应用程序的main方法在JobManager上执行。每个应用程序创建集群可以
    看作是创建仅在特定应用程序的作业之间共享的会话集群，并且在应用程序完成时被拆除。通过这种体系结构，应用程序模式可以提供与逐作业模式相同的资源隔离
    和负载平衡保证，但要保证整个应用程序的粒度。在JobManager上执行main可以节省所需的CPU周期，还可以节省本地下载依赖项所需的带宽。此外，由于每个
    应用程序只有一个JobManager，因此它可以更均匀地分散下载群集中应用程序的依赖项的网络负载。
    注意：在应用程序模式下，main在集群JobManager上而不是在客户端上执行。这可能会对您的代码产生影响，例如，您必须使用应用程序的JobManager访问使用registerCachedFile在环境中注册的任何路径。
    与逐作业模式相比，应用程序模式允许提交包含多个作业的应用程序。作业执行的顺序不受部署模式的影响，但受启动作业的调用的影响。使用被阻塞的execute可以建立一个命令，这将导致“下一个”作业的执行被推迟到“该”作业完成为止。使用非阻塞的executeAsync（）会导致“下一个”作业在“此”作业完成之前开始



通过在Flink命令中指定“savepoint”关键字来触发Savepoints操作，同时需要在命令中指定jobId和targetDirectory（两个参数），其中jobId是需要触发Savepoints操作的Job Id编号，targetDirectory指定Savepoint数据存储路径，所有Savepoint存储的数据都会放置在该配置路径中。
    bin/flink savepoint :jobId [:targetDirectory]
在Hadoop Yarn上提交的应用，需要指定Flink jobId的同时也需要通过使用yid指定YarnAppId，其他参数和普通模式一样。
    bin/flink savepoint :jobId [:targetDirectory] -yid :y
通过cancel命令将停止Flink任务的同时将自动触发Savepoints操作，并把中间状态数据写入磁盘，用以后续的任务恢复。
    bin/flink cancel -s [:targetDirectory] :j

bin/flink run -s :savepointPath [:runArgs]
通过使用run命令将任务从保存的Savepoint中恢复，其中-s参数指定了Savepoint数据存储路径。通常情况下Flink通过使用savepoint可以恢复应用中的状态数据，
但在某些情况下如果应用中的算子和Savepoint中的算子状态可能不一致，例如用户在新的代码中删除了某个算子，这时就会出现任务不能恢复的情况，
此时可以通过--allowNonRestoredState（--n）参数来设置忽略状态无法匹配的问题，让程序能够正常启动和运行。

bin/flink savepoint -d :savepointPath
可以通过以上--dispose（-d）命令释放已经存储的Savepoint数据，这样存储在指定路径中的savepointPath将会被清除掉。

启动一个监听端口
    $ nc -l 9000
flink提交任务
    $ ./bin/flink run examples/streaming/SocketWindowWordCount.jar --port 9000

    $ ./bin/stop-local.sh

flink on yarn: https://my.oschina.net/u/3522232/blog/2051960
     需要拷贝：jersey*,
    export HADOOP_CLASSPATH="/usr/hdp/current/hadoop-client/*:/usr/hdp/current/hadoop-client/lib/*:/usr/hdp/current/hadoop-hdfs-client/*:/usr/hdp/current/hadoop-hdfs-client/lib/*:/usr/hdp/current/hadoop-yarn-client/*:/usr/hdp/current/hadoop-yarn-client/lib/*"
    export HADOOP_USER_NAME=hdfs

    启动yarn session,可以提交多个作业
    yarn session -q可以查看集群资源状态

    ./bin/yarn-session.sh -n 10 -tm 2048 -s 2  前台运行，ctrl + c停止即可
    yarn-session.sh -n 3 -jm 2048 -tm 2048 -s 8 -nm FlinkOnYarnSession -d -st

    -d参数可以后台运行，需要 yarn application -kill 关闭
    绑定到已有的yarn session命令：./bin/yarn-session.sh -id application_1463870264508_0029

    请注意：client期望设置-yn 参数(taskmanager的数量)推荐每次创建yarn cluster独立管理
    ./bin/flink run -m yarn-cluster -yn 2 ./examples/batch/WordCount.jar
    ./bin/flink run -m yarn-cluster -yn 2 -c mumu.SocketWordCount /opt/test-1.0-SNAPSHOT.jar --port 11199

    修改flink默认日志
    vi /usr/local/flink-1.3.3/conf/log4j.properties
    log4j.appender.file.append=true
    log4j.appender.file.MaxFileSize=100M
    log4j.appender.file.MaxBackupIndex=10
    flink的日志会应用到每个flink应用程序上


flink run参数
    -c,--class
    -C,--classpath
    -d,--detached  If present, runs the job in detached mode
    -n,--allowNonRestoredState	告诉Flink系统不用所有节点都进行restore
    -p,--parallelism
    -s,--fromSavepoint   Path to a savepoint to restore the job from (for example hdfs:///flink/savepoint-1537).
    -sae,--shutdownOnAttachedExit
    -m,--jobmanager   Address of the JobManager (master) to which to connect
    -yD <property=value>   use value for given property
    -yd,--yarndetached   If present, runs the job in detached mode
    -yh,--yarnhelp	 Help for the Yarn session CLI.
    -yid,--yarnapplicationId   Attach to running YARN session
    -yj,--yarnjar	 Path to Flink jar file
    -yjm,--yarnjobManagerMemory	 Memory for JobManager Container with optional unit (default: MB)
    -yn,--yarncontainer	 Number of YARN container to allocate (=Number of Task Managers)
    -ynl,--yarnnodeLabel	 Specify YARN node label for the YARN application
    -ynm,--yarnname	  Set a custom name for the application on YARN
    -yq,--yarnquery	 Display available YARN resources (memory, cores)
    -yqu,--yarnqueue	 Specify YARN queue.
    -ys,--yarnslots	 Number of slots per TaskManager
    -yst,--yarnstreaming	 Start Flink in streaming mode
    -yt,--yarnship	 Ship files in the specified directory (t for transfer)
    -ytm,--yarntaskManagerMemory	 Memory per TaskManager Container with  optional unit (default: MB)
    -yz,--yarnzookeeperNamespace	 Namespace to create the Zookeeper sub-paths for high availability mode

yarn-session.sh参数
    -at,--applicationType	Set a custom application type for the application on YARN
    -n,--container	 Number of YARN container to allocate (=Number of Task Managers)
    -D <property=value> 	use value for given property
    -d,--detached	If present, runs the job in detached mode
    -h,--help 	Help for the Yarn session CLI.
    -id,--applicationId	Attach to running YARN session
    -j,--jar  	Path to Flink jar file
    -jm,--jobManagerMemory	Memory for JobManager Container with optional unit (default: MB)
    -m,--jobmanager  	Address of the JobManager (master) to which to connect.
    -nm,--name	Set a custom name for the application on YARN
    -q,--query	Display available YARN resources (memory, cores)
    -s,--slots  	Number of slots per TaskManager
    -qu,--queue	Specify YARN queue.
    -tm,--taskManagerMemory	Memory per TaskManager Container with optional unit (default: MB)
    -yd,--yarndetached	If present, runs the job in detached mode (deprecated; use non-YARN specific option instead)

   yarn-session模式
        启动一个session：1个taskmanager，jobmanager内存1G，taskmanager内存1G
           yarn-session.sh -n 1 -jm 1024 -tm 1024
           控制台日志最后会显示jobmanager地址
           提交任务： 在提交yarn-session的这个主机上提交：
              bin/flink run ~/flink-demo-wordcount.jar
           注意：其他节点主机不能提交,要提交的话指定-m参数指定jobmanager地址
              bin/flink run -m vmhome10.com:43258 examples/batch/WordCount.jar
           可以在flink的web管理页面上提交
           可以启动多个yarn session，一个yarn session模式对应一个JobManager,并按照需求提交作业，同一个Session中可以提交多个Flink作业。

        对于-d分离式模式，并不像客户端那样可以启动多个yarn session，如果启动多个，会出现下面的session一直处在等待状态。JobManager的个数只能是一个，同一个Session中可以提交多个Flink作业。
   Flink run 方式提交（推荐模式）
        yarn session需要先启动一个集群，然后在提交作业。
        对于Flink run直接提交作业就相对比较简单，不需要额外的去启动一个集群，直接提交作业，即可完成Flink作业。
        bin/flink run -m yarn-cluster examples/batch/WordCount.jar，注意使用参数-m yarn-cluster提交到yarn集群。
        可以指定 -yid,--yarnapplicationId <arg> Attach to running YARN session来附加到到特定的yarn session上运行

   从1.5版本开始，Flink on YARN时的容器数量——亦即TaskManager数量——将由程序的并行度自动推算，
      也就是说flink run脚本的-yn/--yarncontainer参数不起作用了
   Flink程序中设定并行度有4种级别，从低到高分别为：算子级别、执行环境（ExecutionEnvironment）级别、客户端（命令行）级别、配置文件（flink-conf.yaml）级别。实际执行时，优先级则是反过来的，算子级别最高。

   container数量 = taskManager数量 + 1 = max(parallelNum) / slotNumPerTaskManager


    a、local模式
         flink run -c com.test.WordCount2 ./Flink.jar
    b、standalone模式
         flink run -m artemis-02:6123 -c com.test.WordCount2 ./Flink.jar  hdfs://artemis-02:9000/tmp/lvxw/tmp/logs/words hdfs://artemis-02:9000/tmp/lvxw/tmp/out
    c、flink on yarn模式
         flink run -m yarn-cluster -yn 2 -yjm 1024 -ytm 1024 -c com.test.WordCount2 ./Flink.jar  hdfs://artemis-02:9000/tmp/lvxw/tmp/logs/words hdfs://artemis-02:9000/tmp/lvxw/tmp/out















flink 的 yarn 客户端通过下面的配置参数来控制容器的故障恢复。这些参数可以通过conf/flink-conf.yaml 或者在启动yarn session的时候通过-D参数来指定。
    yarn.reallocate-failed：这个参数控制了flink是否应该重新分配失败的taskmanager容器。默认是true。
	yarn.maximum-failed-containers：applicationMaster可以接受的容器最大失败次数，达到这个参数，就会认为yarn session失败。默认这个次数和初始化请求的taskmanager数量相等(-n 参数指定的)。
	yarn.application-attempts：applicationMaster重试的次数。如果这个值被设置为1(默认就是1)，当application master失败的时候，yarn session也会失败。设置一个比较大的值的话，yarn会尝试重启applicationMaster。



flink metrics:
      TaskManagerMetricGroup
          TaskManagerJobMetricGroup
                TaskMetricGroup
                     TaskIOMetricGroup
                     OperatorMetricGroup
      JobManagerMetricGroup
          JobManagerJobMetricGroup

   System metrics:
         Master 级别和 Work 级别的 JVM 参数
         Network
   User-defined Metrics:
         User-defined Metrics 现在提及的都是 datastream 的 API，table、sql 可能需要 context 协助，但如果写 UDF，它们其实是大同小异的
         Datastream 的 API 是继承 RichFunction ，继承 RichFunction 才可以有 Metrics 的接口。然后通过 RichFunction 会带来一个 getRuntimeContext().getMetricGroup().addGroup(…) 的方法
   获取metrics:
         1、 WebUI 上看到
         2、其次可以通过 RESTful API 获取，RESTful API 对程序比较友好，比如写自动化脚本或程序，自动化运维和测试，通过 RESTful API 解析返回的 Json 格式对程序比较友好
         3、最后，还可以通过 Metric Reporter 获取，监控主要使用 Metric Reporter 功能。
   了解背景和原理会对使用有更深刻的理解。
         WebUI 和 RESTful API 是通过中心化节点定期查询把各个组件中的 Metrics 拉上来的实现方式。其中，fetch 不一定是实时更新的，默认为 10 秒，所以有可能在 WebUI 和 RESTful API 中刷新的数据不是实时想要得到的数据；
         此外，fetch 有可能不同步，比如两个组件，一边在加另一边没有动，可能是由于某种原因超时没有拉过来，这样是无法更新相关值的，它是 try best 的操作，所以有时我们看到的指标有可能会延迟，或许等待后相关值就更新了。
         MetricReporter 不一样，每一个单独的点直接汇报，它没有中心化节点帮助做聚合。如果想要聚合，需要在第三方系统中进行，比如常见的 TSDB 系统。当然，不是中心化结构也是它的好处，它可以免去中心化节点带来的问题，比如内存放不下等
            metrics.reporters: your_monitor,jmx
            metrics.reporter.jmx.class: org.apache.flink.metrics.jmx.JMXReporter
            metrics.reporter.jmx.port: 1025-10000
            metrics.reporter.your_monitor.class: com.your_company.YourMonitorClass
            metrics.reporter.your_monitor.interval: 10 SECONDS
            metrics.reporter.your_monitor.config.a: your_a_value
            metrics.reporter.your_monitor.config.b: your_b_value




