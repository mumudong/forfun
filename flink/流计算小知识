flink源码教程
    https://blog.csdn.net/qq_22222499/category_9290990.html
    https://www.imooc.com/article/254019

1、flink和storm同样是真实流计算,为什么flink比storm快呢?
   首先,单单就数据计算来说,速度是一样的
    1> 数据传输优化,分为进程间和进程内
     进程间：一般包含shuffle过程,主要是序列化和网络传输
            flink一般是两个TM之间的传输,由netty实现
            storm一般是worker间传输,早期通过zeroMq实现,后来也改成了netty
            flink有自己的一套序列化机制,做了很多优化
     进程内：flink多个逻辑之间可通过chain机制,通过一个task处理多个算子,通过方法调用传参的形式传输数据
           storm两个线程分别运行两个逻辑,通过共享队列传输数据
           flink未chain在一起的算子,上游算子将计算结果序列化后存入内存,然后通过网络传给下游,下游反序列化后继续处理
         chain在一起的算子在一个task内运行,通过对象的深拷贝来实现传输,如果使用env.getConfig().enableObjectReuse()
         会把中间深拷贝的步骤都省略掉,必须确保下游function只有一种或者下游function不改对象内部的值,否则会有线程安全问题
    2> 可靠性
       storm使用ack机制保证数据可靠,flink使用基于chandy-lamport算法的checkpoint
       storm的ack：spout每发一条数据,会产生一条ack信息给acker,bolt处理完该条数据也会发送ack信息给acker,acker收到所有信息
     会回复spout一条ack信息。对于只有一个spout+bolt的拓扑来说,每发一条数据,就会传输3条ack信息
       flink中checkpoint信息的发起者是jobManager,它是按时间来计算花销,用户可设置checkpoint频率,比如10s做一次。每次checkpoint
     花销只有从source发往map的1条checkpoint(jobManager发出的checkpoint信息走的是控制流,与数据流无关)。与storm相比开销要低得多

   总结：实际场景中有很多业务逻辑,会涉及到CPU、内存等问题对整体延迟的影响,flink有自己的一套内存管理机制,也给flink带来性能提升




异步IO：https://www.jianshu.com/p/d8f99d94b761
flink checkpoint:存储operator的state数据
flink barrier对齐：https://blog.csdn.net/weixin_32265569/article/details/108743084
flink两阶段提交和一致性保障：https://mp.weixin.qq.com/s?__biz=MzU5MTc1NDUyOA==&mid=2247483818&idx=1&sn=8c7bf4d00e81d7635bfa26b78a78ebba&chksm=fe2b65e5c95cecf349d9819fe6c998359cb9a8695abbdf74e326adc0503c8f330a2d47182b63&scene=21#wechat_redirect

flink state:
   managed state:
     flink runtime托管,自动存储,自动恢复,自动伸缩,修改应用并行度时状态自动重新分布到多个实例
     flink提供常用的数据结构,如ListState、MapState
     适用绝大多数flink算子,通过集成Rich函数类或其他提供好的接口类
     分为两种：下列两种状态由算子子任务维护状态存储,子任务建状态不能互相访问

        keyed state:
           应用在keyedStream上,每个key有自己的状态
           创建和访问方式: keyed state可通过重写rich function接口,在里面通过runtimeContext创建和访问状态
           横向扩展:状态随key自动在算子子任务上迁移
           支持的数据结构:ValueState/ListState/MapState
           使用方法：
               State主要有三种实现:ValueState
                                MapState
                                AppendingState->ListState、ReducingState、AggregatingState
        operator state:
           应用在所有算子上,每个算子子任务(或者说算子实例)共享一个状态,流入该任务的数据可访问和更新该状态
           创建和访问:operator state需要进一步实现checkpointedFunction接口
           横向扩展:有多种状态重新分配的方式,1:均匀分配,2:所有状态合并再分发给每个实例
           支持的数据结构:ListState/BroadcastState
           使用方法：用途不如keyed state多,常用在source和sink中,用来保存流入数据的偏移量或对输出数据做缓存以保证exactly once
               operator state主要有三种:ListState:按round ribon均匀分配到各算子子任务,每个算子得到整列表的一个子集
                                      UnionListState:广播模式,整个列表传递给所有子任务
                                      BroadcastState


   raw state:
     用户自己管理状态
     数据结构byte[]
     使用场景:已有算子和managed stage不够用时用户自定义算子

window:
    为什么mergewindow
    session window:早期需用户做大量工作实现,新元素到达时基于时间戳注册定时间,并移除上一次的定时器,如果超时时间内还没有新元素到达,就会触发session window
                但是这种方式无法处理乱序数据,flink 1.1.0之后通过sessionWindows.withGap()定义session window,且可处理乱序
           底层原理:会为每个进入的元素分配一个窗口,以元素时间戳为起始,时间戳+会话超时时间为结束
                  假如前两条数据进入两个不相交的窗口,当第三个元素进入,该窗口与前两个窗口相交,会进行合并
                  合并内容: 窗口的底层状态的合并(窗口中缓存的数据,或对聚合窗口来说是一个聚合之)
                          需要合并的窗口的trigger的合并(如对eventTime来说,会删除旧窗口注册的定时器,并注册新窗口的定时器)
                  注意: 每进入一个新元素,都会分配一个该元素的窗口,检查合并现有窗口.触发窗口计算之前,每次都会检查窗口是否可以和其他窗口合并
                       直到trigger触发后,将窗口从窗口列表溢出,对event time来说,触发是要大于窗口结束时间的watermark到达,
                       watermark没到,窗口会一直缓存,基于此可实现对乱序消息的支持













